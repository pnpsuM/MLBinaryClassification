{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE = 'Reference'\n",
    "PROJECT = 'Project'\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from model.model import *\n",
    "from process_func import *\n",
    "import process_func_ref as ref\n",
    "import os\n",
    "DATA_DIR = f'datasets/'\n",
    "map = {'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Major': 'Military', \n",
    "       'Col': 'Military', 'Dr' : 'Other', 'Rev' : 'Other', 'Capt': 'Military', \n",
    "       'Jonkheer': 'Royal', 'Sir': 'Royal', 'Lady': 'Royal', \n",
    "       'Don': 'Royal', 'Countess': 'Royal', 'Dona': 'Royal'}\n",
    "titles =['Miss', 'Mr', 'Mrs', 'Royal', 'Other', 'Master', 'Military']\n",
    "\n",
    "# Run for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "Data Loaded.\n",
      "Data Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deep\\Documents\\GitHub\\MLBinaryClassification\\process_func.py:90: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cnt /= len(group_df.loc[group_df['Type'] != 'test'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Sex', 'Type', 'Title', 'Family_Size', 'Baby', 'Elder', 'Family_Survival']\n",
      "Done Preprocessing.\n",
      "Returned Data Dictionary\n",
      "Initializing...\n",
      "Data Loaded.\n",
      "Data Preprocessing...\n",
      "Done Preprocessing.\n",
      "Returned Data Dictionary\n"
     ]
    }
   ],
   "source": [
    "prepath = 'preprocessed'\n",
    "try:\n",
    "    if not os.path.exists(prepath):\n",
    "        os.makedirs(prepath)\n",
    "except OSError:\n",
    "    print('Error Creating Directory...')\n",
    "    \n",
    "data = Titanic(DATA_DIR, show_head = False)\n",
    "data.Preprocess(map, titles, PROJECT)\n",
    "data._data.to_csv(prepath + f\"/encoded_{PROJECT}.csv\", index = False)\n",
    "dataset = data.GetXandY()\n",
    "\n",
    "data_ref = ref.Titanic(DATA_DIR, show_head = False)\n",
    "data_ref.Preprocess(map, titles, REFERENCE)\n",
    "data_ref._data.to_csv(prepath + f\"/encoded_{REFERENCE}.csv\", index = False)\n",
    "dataset_ref = data_ref.GetXandY()\n",
    "\n",
    "# Run for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ReferenceModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 16)]              0         \n",
      "                                                                 \n",
      " Dense0 (Dense)              (None, 16)                272       \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 8)                 136       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ref_model = ReferenceModel(dataset_ref['x_train'].shape)\n",
    "CP_dir_ref = SetCheckpoint(REFERENCE)\n",
    "TB_dir_ref = SetLog(REFERENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ProjectModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 19)]              0         \n",
      "                                                                 \n",
      " Dense0 (Dense)              (None, 16)                320       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " Dense2 (Dense)              (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 897\n",
      "Trainable params: 817\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "proj_model = ProjectModel(dataset['x_train'].shape)\n",
    "CP_dir_proj = SetCheckpoint(PROJECT)\n",
    "TB_dir_proj = SetLog(PROJECT)\n",
    "# Run for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 300\n",
    "callbacks_ref = DefCallbacks(REFERENCE, CP = CP_dir_ref, TB = TB_dir_ref)\n",
    "history_ref = ref_model.fit(dataset_ref['x_train'], dataset_ref['y_train'], callbacks = callbacks_ref, \n",
    "          validation_split = 0.2, batch_size=BATCH_SIZE, epochs = EPOCHS, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 300\n",
    "callbacks_proj = DefCallbacks(PROJECT, CP = CP_dir_proj, TB = TB_dir_proj)\n",
    "history_proj = proj_model.fit(dataset['x_train'], dataset['y_train'], callbacks = callbacks_proj, \n",
    "          validation_split = 0.2, batch_size=BATCH_SIZE, epochs = EPOCHS, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n",
      "0    0.106543\n",
      "1    0.785456\n",
      "2    0.132468\n",
      "3    0.160796\n",
      "4    0.961181\n",
      "5    0.119287\n",
      "6    0.732761\n",
      "7    0.102865\n",
      "8    0.577484\n",
      "9    0.045303\n",
      "dtype: float32\n",
      "ReferenceModel_Accuracy :  79.90 %\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "0    0.154492\n",
      "1    0.431652\n",
      "2    0.120504\n",
      "3    0.154492\n",
      "4    0.535362\n",
      "5    0.154492\n",
      "6    0.497960\n",
      "7    0.127375\n",
      "8    0.634350\n",
      "9    0.131153\n",
      "dtype: float32\n",
      "ProjectModel_Accuracy :  79.19 %\n"
     ]
    }
   ],
   "source": [
    "submission = PerformanceCheck(ref_model, CP_dir_ref, dataset_ref['x_test'], DATA_DIR)\n",
    "submission.to_csv(f\"submission/submission_{REFERENCE}.csv\", index = False)\n",
    "submission = PerformanceCheck(proj_model, CP_dir_proj, dataset['x_test'], DATA_DIR)\n",
    "submission.to_csv(f\"submission/submission_{PROJECT}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
